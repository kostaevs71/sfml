{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Подключаем нужные библиотеки\n",
    "import multiprocessing \n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pymorphy2\n",
    "\n",
    "import queue\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для начала просто попробуем как работает multithreading.queue .\n",
    "Данный класс позволяет обмениваться информацией между потоками. При этом если поток-поставщик данных работает быстрее, то данные будут \"складироваться\" в очереди, пока потребитель их не заберет.\n",
    "Размер очереди может быть ограничен. В этом случае операция \"положить в очередь\" заблокирует поток, если очередь заполнена.\n",
    "Если очередь пуста, поток, запросивший данные также будет заблокирован при запросе данных. \n",
    "Для избежания блокировок можно использовать timeout (через какое время поток будет разблокирован и фцнкция сообщит о неуспехе).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# создадим очередь\n",
    "cntr=0\n",
    "exch=multiprocessing.Queue(5)\n",
    "random.seed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 0\n",
      "read 0\n",
      "wrote 1\n",
      "read 1\n",
      "wrote 2\n",
      "read 2\n",
      "wrote 3\n",
      "read 3\n",
      "wrote 4\n",
      "wrote 5\n",
      "read 4\n",
      "wrote 6\n",
      "read 5\n",
      "wrote 7\n",
      "read 6\n",
      "wrote 8\n",
      "read 7\n",
      "read 8\n",
      "wrote 9\n",
      "read 9\n",
      "read 11\n"
     ]
    }
   ],
   "source": [
    "# У нас будет два потока. \n",
    "# Writer будет писать даные в очередь через случайные промежутки времени. \n",
    "def writer():\n",
    "  global cntr\n",
    "  while cntr<10: #пишем 10 чисел\n",
    "    exch.put(cntr) # собственно пишем в очередь\n",
    "    print('wrote '+str(cntr)) # отчитываемся о записи.\n",
    "    cntr+=1\n",
    "    time.sleep(random.random()) # засыпаем на случайный промежуток времени.\n",
    "  exch.put(11) # конец данных.\n",
    "  \n",
    "# Reader в параллельном потоке читает из очереди через случайные промежутки времени.\n",
    "def reader():\n",
    "  i=-1\n",
    "  while i<10: # пока прочитанное число меньше 10...\n",
    "    i=exch.get() # Собственно читаем из очереди.\n",
    "    print('read '+str(i)) # Отчитываемся.\n",
    "    time.sleep(random.random()) # спмм\n",
    "  \n",
    "# создаем, а потом запускаем потоки.\n",
    "pr1=multiprocessing.Process(target=writer)\n",
    "pr2=multiprocessing.Process(target=reader)\n",
    "pr1.start()\n",
    "pr2.start()\n",
    "\n",
    "# Видно, как потоки работают параллельно, правда?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Теперь попробуем решить следующую задачу.\n",
    "Необходимо получать новости из нескольких источников. Далее каждая новость токенизируется в отдельном потоке, лемматизируется в еще одном потоке. В конце идет поток, который обрабатывает полученные данные.\n",
    "Новости также получаются в отдельных потоках.\n",
    "\n",
    "Для передачи данных используем очередь. \n",
    "Для сигнализации завершения работы потоков используем события и семафоры.\n",
    "Событие может быть установлено или сброшено. Если поток пытается установить установленное или сбросить сброшенное событие, он блокируется (но может быть разблокирован по тайм-ауту).\n",
    "Семафор фактически хранит информацию о нескольких событиях, то есть у семафора есть некоторый объем. Процесс блокируется при запросе ресурса из семафрра, только если тот уже был запрошен n раз и ресурс исчерпан.\n",
    "\n",
    "Использование очереди, событий и семафоров позволяет синхронизировать операции в потоках. Токенизатор начнет разбор только после того, как очередь получит данные от одного из загрузчиков новостей. Результат будет помещен в другую очередь. Токенизатор \"уснет\" до тех пор, пока не придет еще одна новость, зато \"проснется\" лемматизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !!!===--- ВНИМАНИЕ!!! ---===!!!\n",
    "# Код в данной ячейке работает некорректно, так как завершение процессов вызывает взаимную  блокировку!\n",
    "# Корректный вариант синхронизации показан ниже.\n",
    "\n",
    "\n",
    "# Функция для загрузки одной новости из Ленты.ру\n",
    "def getLentaArticle(url):\n",
    " \"\"\" getLentaArticle gets the body of the article from Lenta.ru\"\"\"\n",
    " r = requests.get(url)\n",
    " body=re.findall('<div class=\"b-text clearfix js-topic__text\" itemprop=\"articleBody\">(.+?)</p></div></div><section class=\"b-topic__socials js-topic__socials\">', r.text)\n",
    " if len(body)>0:\n",
    "  return BeautifulSoup(body[0], \"lxml\").get_text()\n",
    " else:\n",
    "    return \"  \"\n",
    "\n",
    "# Функция загрузки одной новости из N+1.\n",
    "def getArticleTextNPlus1(adr):\n",
    " r = requests.get(adr)\n",
    " n_text=re.split(\"</div>\", re.split(\"</figure>\", re.split('</article>',re.split('<article', r.text)[1])[0])[1])[1]    \n",
    " return BeautifulSoup(n_text, \"lxml\").get_text()\n",
    "\n",
    "# Загрузка новостей из Ленты.ру за некоторый период.\n",
    "def getLenta(qu, sem):\n",
    " curdate=datetime.date(2017, 1, 16)\n",
    " findate=datetime.date(2017, 1, 16)\n",
    " res=\"\"\n",
    "\n",
    "# Загружаем новости до конечной даты.\n",
    " while curdate<=findate:\n",
    "  print('lenta '+curdate.strftime('%Y/%m/%d'))\n",
    "  day = requests.get('https://lenta.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "  body=re.findall('<h3>(.+?)</h3>', day.text)\n",
    "  links=['https://lenta.ru'+re.findall('\"(.+?)\"', x)[0] for x in body]\n",
    "  for l in links: # идем по всем ссылкам на новости за день.\n",
    "    qu.put(getLentaArticle(l)) # Полученную новость кладем в очередь.\n",
    "    time.sleep(0.2)\n",
    "  curdate+=datetime.timedelta(days=1)\n",
    " sem.acquire() # Блокируем семафор один раз, по\n",
    " print(\"lenta finished\")\n",
    "\n",
    "# Получаем новости с NPlus1 за заданный промежуток времени, кладем тексты новостей в очередь qu.\n",
    "# По завершении взводим семафор sem.\n",
    "def getNplus1(qu, sem):\n",
    " curdate=datetime.date(2015, 12, 15)\n",
    " findate=datetime.date(2015, 12, 19)\n",
    "\n",
    " while curdate<=findate: # Перебираем все дни.\n",
    "  r = requests.get('https://nplus1.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "  print('nplus '+curdate.strftime('%Y/%m/%d'))\n",
    "  # Берем заголовки и ссылки на новости за этот день.\n",
    "  refs=[re.split('\"', t)[6] for t in re.split('<article class=\"item item-news item-news', r.text)[1:]]\n",
    "  for t in refs:\n",
    "   qu.put(getArticleTextNPlus1(\"https://nplus1.ru\"+t)) # Получаем текст статьи и отправляем в очередь.\n",
    "   time.sleep(0.2) # Мы этичные хакеры и не стремимся к DDoS.\n",
    "  curdate+=datetime.timedelta(days=1)\n",
    " sem.acquire() # Взводим семафор.\n",
    " print(\"nplus1 finished\")\n",
    "    \n",
    "# Функция токенизирует вход из очереди qu1 и кладет результаты токенизации в очередь qu2.\n",
    "# Токенизация ведется до тех пор, пока семафор semw не будет взведен максимальное количество раз.\n",
    "# По завершении токенизации устанавливаем событие evs.\n",
    "def tokenize(qu1, qu2, semw, evs):  \n",
    "    c=0\n",
    "    # Пытаемся взвести семафор. Если не взведется, значит все потоки завершились (взведением семафора).\n",
    "    while semw.acquire(False): \n",
    "        txt=qu1.get() # Получаем данные из очереди.\n",
    "        semw.release() # Отпускаем семафор (мы же взвели его в while).\n",
    "        qu2.put(re.findall(\"[А-Яа-я]+(-[А-Яа-я]+)?\", txt)) # ОЧень простая токенизация кладет результаты в очередь.\n",
    "        c+=1\n",
    "        print('token '+str(c))\n",
    "    print(\"tokenization finished\")\n",
    "    evs.set() # Сообщаем о завершении работы установкой события.\n",
    "    print(\"tokenization finished\")\n",
    "\"\"\" Вот здесь-то и происходит блокировка.\n",
    "    while semw.acquire(False): блокирует семафор для потоков, поставляющих новости. В самом конце последний \n",
    "    поток с новостями заканчивает свою работу и пытается завершиться. Но семафор уже заполнен, и поток переводится\n",
    "    в состояние ожидания. При этом поток токенизации ждет получения данных txt=qu1.get(), но так как данные не \n",
    "    больше поступают, то он тоже блокируется. \n",
    "    Один поток ждет данных, чтобы продолжить работу и разблокировать семафор, другой заблокирован семафором и \n",
    "    больше не хочет отправлять данные. Клинч! Хорошо хоть, что в конце работы, но такое могло произойти и в середине.\n",
    "    \n",
    "    Ниже приведен код, который исправляет эту ситуацию.\n",
    "\"\"\"\n",
    "\n",
    "# Поток лемматизации текстов. Токены берутся из очереди qu1, результаты лемматизации кладутся в qu2.\n",
    "# Так как новости приходят по одной в токенизацию, скорее всего токены будут идти подряд. Но если вдруг у нас появится\n",
    "# еще один поток для токенизации, они начнут помещаться в очередь вперемешку. Так что такая технология подходит\n",
    "# только если нас не волнуется порядок слов.\n",
    "# Данный заканчиваются, когда будет установлено событие evw, сообщаем о своем завершении при помощи события evs.\n",
    "def lemmatize(qu1, qu2, evw, evs):\n",
    "    morpho=pymorphy2.MorphAnalyzer() # Создаем морфоанализатор.\n",
    "    l=[]\n",
    "    c=0\n",
    "    while not evw.is_set(): # Если событие установлено - пора завершать работу.\n",
    "        txt=qu1.get()\n",
    "        s=[]\n",
    "        for w in txt:\n",
    "            s+=morpho.parse(w)[0]\n",
    "        qu2.put(s) # Анализиируем, кладем результат в очередь.\n",
    "        c+=1\n",
    "        print('lemma '+str(c))\n",
    "    evs.set() # ЗАвершаем работу.\n",
    "    print(\"lemmatization finished\")\n",
    "\n",
    "# Функция имитирует, что она обрабатывает данные из очереди qu. Заершает работу по событию ev.    \n",
    "def utilize(qu, ev):\n",
    "    c=0\n",
    "    while not ev.is_set(): # Если событие установлено - пора завершать работу.\n",
    "        t=qu.get()\n",
    "        #processing\n",
    "        c+=1\n",
    "        print('process '+str(c))\n",
    "    print('processing finished')\n",
    "\n",
    "# не надо тормозить при получении данных из очереди,\n",
    "# надо поставить ожидание если очередь пуста.\n",
    "# то, что есть - хороший пример на сложности синхронизации. еще очередь поменьше сделай.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenta 2017/01/16\n",
      "nplus 2015/12/15\n",
      "token 1\n",
      "lemma 1\n",
      "process 1\n",
      "token 2\n",
      "lemma 2\n",
      "process 2\n",
      "token 3\n",
      "lemma 3\n",
      "process 3\n",
      "token 4\n",
      "lemma 4\n",
      "process 4\n",
      "token 5\n",
      "lemma 5\n",
      "process 5\n",
      "token 6\n",
      "lemma 6\n",
      "process 6\n",
      "token 7\n",
      "lemma 7\n",
      "process 7\n",
      "token 8\n",
      "lemma 8\n",
      "process 8\n",
      "token 9\n",
      "lemma 9\n",
      "process 9\n",
      "token 10\n",
      "lemma 10\n",
      "process 10\n",
      "token 11\n",
      "lemma 11\n",
      "process 11\n",
      "token 12\n",
      "lemma 12\n",
      "process 12\n",
      "token 13\n",
      "lemma 13\n",
      "process 13\n",
      "token 14\n",
      "lemma 14\n",
      "process 14\n",
      "token 15\n",
      "lemma 15\n",
      "process 15\n",
      "token 16\n",
      "lemma 16\n",
      "process 16\n",
      "token 17\n",
      "lemma 17\n",
      "process 17\n",
      "token 18\n",
      "lemma 18\n",
      "process 18\n",
      "token 19\n",
      "lemma 19\n",
      "process 19\n",
      "token 20\n",
      "lemma 20\n",
      "process 20\n",
      "token 21\n",
      "lemma 21\n",
      "process 21\n",
      "token 22\n",
      "lemma 22\n",
      "process 22\n",
      "token 23\n",
      "lemma 23\n",
      "process 23\n",
      "token 24\n",
      "lemma 24\n",
      "process 24\n",
      "token 25\n",
      "lemma 25\n",
      "process 25\n",
      "token 26\n",
      "lemma 26\n",
      "process 26\n",
      "token 27\n",
      "lemma 27\n",
      "process 27\n",
      "lemma 28\n",
      "process 28\n",
      "token 28\n",
      "token 29\n",
      "lemma 29\n",
      "process 29\n",
      "token 30\n",
      "lemma 30\n",
      "process 30\n",
      "token 31\n",
      "lemma 31\n",
      "process 31\n",
      "token 32\n",
      "lemma 32\n",
      "process 32\n",
      "token 33\n",
      "lemma 33\n",
      "process 33\n",
      "token 34\n",
      "lemma 34\n",
      "process 34\n",
      "token 35\n",
      "lemma 35\n",
      "process 35\n",
      "token 36\n",
      "lemma 36\n",
      "process 36\n",
      "token 37\n",
      "lemma 37\n",
      "process 37\n",
      "token 38\n",
      "lemma 38\n",
      "process 38\n",
      "token 39\n",
      "lemma 39\n",
      "process 39\n",
      "token 40\n",
      "lemma 40\n",
      "process 40\n",
      "token 41\n",
      "lemma 41\n",
      "process 41\n",
      "token 42\n",
      "lemma 42\n",
      "process 42\n",
      "token 43\n",
      "lemma 43\n",
      "process 43\n",
      "token 44\n",
      "lemma 44\n",
      "process 44\n",
      "token 45\n",
      "lemma 45\n",
      "process 45\n",
      "nplus 2015/12/16\n",
      "token 46\n",
      "lemma 46\n",
      "process 46\n",
      "token 47\n",
      "lemma 47\n",
      "process 47\n",
      "token 48\n",
      "lemma 48\n",
      "process 48\n",
      "token 49\n",
      "lemma 49\n",
      "process 49\n",
      "token 50\n",
      "lemma 50\n",
      "process 50\n",
      "token 51\n",
      "lemma 51\n",
      "process 51\n",
      "token 52\n",
      "lemma 52\n",
      "process 52\n",
      "token 53\n",
      "lemma 53\n",
      "process 53\n",
      "token 54\n",
      "lemma 54\n",
      "process 54\n",
      "token 55\n",
      "lemma 55\n",
      "process 55\n",
      "lemma 56\n",
      "token 56\n",
      "process 56\n",
      "lemma 57\n",
      "token 57\n",
      "process 57\n",
      "token 58\n",
      "lemma 58\n",
      "process 58\n",
      "token 59\n",
      "lemma 59\n",
      "process 59\n",
      "token 60\n",
      "lemma 60\n",
      "process 60\n",
      "token 61\n",
      "lemma 61\n",
      "process 61\n",
      "token 62\n",
      "lemma 62\n",
      "process 62\n",
      "token 63\n",
      "lemma 63\n",
      "process 63\n",
      "token 64\n",
      "lemma 64\n",
      "process 64\n",
      "token 65\n",
      "lemma 65\n",
      "process 65\n",
      "token 66\n",
      "lemma 66\n",
      "process 66\n",
      "token 67\n",
      "lemma 67\n",
      "process 67\n",
      "token 68\n",
      "process 68\n",
      "lemma 68\n",
      "token 69\n",
      "lemma 69\n",
      "process 69\n",
      "token 70\n",
      "lemma 70\n",
      "process 70\n",
      "token 71\n",
      "lemma 71\n",
      "process 71\n",
      "token 72\n",
      "lemma 72\n",
      "process 72\n",
      "nplus 2015/12/17\n",
      "token 73\n",
      "lemma 73\n",
      "process 73\n",
      "token 74\n",
      "lemma 74\n",
      "process 74\n",
      "token 75\n",
      "lemma 75\n",
      "process 75\n",
      "token 76\n",
      "lemma 76\n",
      "process 76\n",
      "token 77\n",
      "lemma 77\n",
      "process 77\n",
      "token 78\n",
      "lemma 78\n",
      "process 78\n",
      "token 79\n",
      "lemma 79\n",
      "process 79\n",
      "token 80\n",
      "lemma 80\n",
      "process 80\n",
      "token 81\n",
      "lemma 81\n",
      "process 81\n",
      "token 82\n",
      "lemma 82\n",
      "process 82\n",
      "token 83\n",
      "lemma 83\n",
      "process 83\n",
      "token 84\n",
      "lemma 84\n",
      "process 84\n",
      "token 85\n",
      "lemma 85\n",
      "process 85\n",
      "token 86\n",
      "lemma 86\n",
      "process 86\n",
      "token 87\n",
      "lemma 87\n",
      "process 87\n",
      "token 88\n",
      "lemma 88\n",
      "process 88\n",
      "token 89\n",
      "lemma 89\n",
      "process 89\n",
      "token 90\n",
      "lemma 90\n",
      "process 90\n",
      "token 91\n",
      "lemma 91\n",
      "process 91\n",
      "token 92\n",
      "lemma 92\n",
      "process 92\n",
      "token 93\n",
      "lemma 93\n",
      "process 93\n",
      "token 94\n",
      "lemma 94\n",
      "process 94\n",
      "token 95\n",
      "lemma 95\n",
      "process 95\n",
      "token 96\n",
      "lemma 96\n",
      "process 96\n",
      "token 97\n",
      "lemma 97\n",
      "process 97\n",
      "token 98\n",
      "lemma 98\n",
      "process 98\n",
      "token 99\n",
      "lemma 99\n",
      "process 99\n",
      "token 100\n",
      "lemma 100\n",
      "process 100\n",
      "token 101\n",
      "lemma 101\n",
      "process 101\n",
      "token 102\n",
      "lemma 102\n",
      "process 102\n",
      "token 103\n",
      "lemma 103\n",
      "process 103\n",
      "lenta finished\n",
      "token 104\n",
      "lemma 104\n",
      "process 104\n",
      "token 105\n",
      "lemma 105\n",
      "process 105\n",
      "token 106\n",
      "lemma 106\n",
      "process 106\n",
      "token 107\n",
      "lemma 107\n",
      "process 107\n",
      "nplus 2015/12/18\n",
      "token 108\n",
      "lemma 108\n",
      "process 108\n",
      "token 109\n",
      "lemma 109\n",
      "process 109\n",
      "token 110\n",
      "lemma 110\n",
      "process 110\n",
      "token 111\n",
      "lemma 111\n",
      "process 111\n",
      "token 112\n",
      "lemma 112\n",
      "process 112\n",
      "token 113\n",
      "lemma 113\n",
      "process 113\n",
      "token 114\n",
      "lemma 114\n",
      "process 114\n",
      "token 115\n",
      "lemma 115\n",
      "process 115\n",
      "token 116\n",
      "lemma 116\n",
      "process 116\n",
      "token 117\n",
      "lemma 117\n",
      "process 117\n",
      "token 118\n",
      "lemma 118\n",
      "process 118\n",
      "token 119\n",
      "lemma 119\n",
      "process 119\n",
      "token 120\n",
      "lemma 120\n",
      "process 120\n",
      "token 121\n",
      "lemma 121\n",
      "process 121\n",
      "token 122\n",
      "lemma 122\n",
      "process 122\n",
      "token 123\n",
      "process 123\n",
      "lemma 123\n",
      "token 124\n",
      "lemma 124\n",
      "process 124\n",
      "token 125\n",
      "lemma 125\n",
      "process 125\n",
      "nplus1 finished\n",
      "tokenization \n",
      "finished\n",
      "lemmatization finished\n",
      "processing finished\n"
     ]
    }
   ],
   "source": [
    "# Два потока новостей.\n",
    "newswirenumber=2\n",
    "\n",
    "# Создаем очереди, семафор и события для синхронизации.\n",
    "textsq=multiprocessing.Queue(100)\n",
    "tokenq=multiprocessing.Queue(100)\n",
    "lemmaq=multiprocessing.Queue(100)\n",
    "newss=multiprocessing.Semaphore(newswirenumber)\n",
    "tokene=multiprocessing.Event()\n",
    "lemmae=multiprocessing.Event()\n",
    "\n",
    "# Запускаем процессы.\n",
    "lentap=multiprocessing.Process(target=getLenta, args=(textsq, newss,))\n",
    "nplusp=multiprocessing.Process(target=getNplus1, args=(textsq, newss,))  \n",
    "tokenp=multiprocessing.Process(target=tokenize, args=(textsq, tokenq, newss, tokene, ))   \n",
    "lemmap=multiprocessing.Process(target=lemmatize, args=(tokenq, lemmaq, tokene, lemmae, ))   \n",
    "processp=multiprocessing.Process(target=utilize, args=(lemmaq, lemmae, ))    \n",
    "    \n",
    "# Стартуем процессы    \n",
    "lentap.start()\n",
    "nplusp.start()\n",
    "tokenp.start()\n",
    "lemmap.start()\n",
    "processp.start()\n",
    "\n",
    "# Если надо - ждем пока процессы не завершатся.\n",
    "#lentap.join()\n",
    "#nplusp.join()\n",
    "#tokenp.join()\n",
    "#lemmap.join()\n",
    "#processp.join()\n",
    "#print(\"Everything is allright\")                               \n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Это код работает более корректно, чем тот, что приведен выше.\n",
    "# Больша часть комментариев опущена, оставлены только те, что помогают понять изменения в логике.\n",
    "\n",
    "def getLentaArticle(url):\n",
    " \"\"\" getLentaArticle gets the body of the article from Lenta.ru\"\"\"\n",
    " r = requests.get(url)\n",
    " body=re.findall('<div class=\"b-text clearfix js-topic__text\" itemprop=\"articleBody\">(.+?)</p></div></div><section class=\"b-topic__socials js-topic__socials\">', r.text)\n",
    " if len(body)>0:\n",
    "  return BeautifulSoup(body[0], \"lxml\").get_text()\n",
    " else:\n",
    "    return \"  \"\n",
    "\n",
    "def getArticleTextNPlus1(adr):\n",
    " r = requests.get(adr)\n",
    " n_text=re.split(\"</div>\", re.split(\"</figure>\", re.split('</article>',re.split('<article', r.text)[1])[0])[1])[1]    \n",
    " return BeautifulSoup(n_text, \"lxml\").get_text()\n",
    "\n",
    "def getLenta(qu, sem):\n",
    " curdate=datetime.date(2017, 1, 16)\n",
    " findate=datetime.date(2017, 1, 16)\n",
    " res=\"\"\n",
    "\n",
    " while curdate<=findate:\n",
    "  print('lenta '+curdate.strftime('%Y/%m/%d'))\n",
    "  day = requests.get('https://lenta.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "  body=re.findall('<h3>(.+?)</h3>', day.text)\n",
    "  links=['https://lenta.ru'+re.findall('\"(.+?)\"', x)[0] for x in body]\n",
    "  for l in links[:50]:\n",
    "    qu.put(getLentaArticle(l))\n",
    "    time.sleep(0.2)\n",
    "  curdate+=datetime.timedelta(days=1)\n",
    " sem.acquire()\n",
    " print(\"lenta finished\")\n",
    "\n",
    "def getNplus1(qu, sem):\n",
    " curdate=datetime.date(2015, 12, 15)\n",
    " findate=datetime.date(2015, 12, 18)\n",
    "\n",
    " while curdate<=findate:\n",
    "  r = requests.get('https://nplus1.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "  print('nplus '+curdate.strftime('%Y/%m/%d'))\n",
    "  refs=[re.split('\"', t)[6] for t in re.split('<article class=\"item item-news item-news', r.text)[1:]]\n",
    "  for t in refs:\n",
    "   qu.put(getArticleTextNPlus1(\"https://nplus1.ru\"+t))\n",
    "   time.sleep(0.2)\n",
    "  curdate+=datetime.timedelta(days=1)\n",
    " sem.acquire()\n",
    " print(\"nplus1 finished\")\n",
    "    \n",
    "# На входе - те же самые очереди, семафор и событие, но используем мы их по-другому.\n",
    "def tokenize(qu1, qu2, semw, evs):  \n",
    "    c=0\n",
    "    while semw.acquire(False): # Так же пытаемся получить семафор.\n",
    "        try:\n",
    "            semw.release() # ! Первым делом отпускаем его, чтобы никого не держать больше.\n",
    "            txt=qu1.get(timeout=0.1) # Если что-то пойдет не так, нас отпустят через 0,1 секунды.\n",
    "        except queue.Empty: # Если произршел выход по таймауту, генерируется исключение.\n",
    "            #print('tokenization waits')\n",
    "            pass # Данных нет, пойдем посмотрим, может вообще завершаться пора?\n",
    "        else:\n",
    "            qu2.put(re.findall(\"[А-Яа-я]+(-[А-Яа-я]+)?\", txt)) # Данные есть - токенизируем и кладем в очередь.\n",
    "            c+=1\n",
    "            print('token '+str(c))\n",
    "\n",
    "    print(\"tokenization \")\n",
    "    evs.set()\n",
    "    print(\"finished\")\n",
    "\n",
    "def lemmatize(qu1, qu2, evw, evs):\n",
    "    morpho=pymorphy2.MorphAnalyzer()\n",
    "    l=[]\n",
    "    c=0\n",
    "    while not evw.is_set():\n",
    "        try:\n",
    "            txt=qu1.get(timeout=0.1) # Поддерживаем логику таймаута везде на всякий случай.\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        else:\n",
    "            s=[]\n",
    "            for w in s:\n",
    "                s+=morpho.parse(w)[0]\n",
    "            qu2.put(s)\n",
    "            c+=1\n",
    "            print('lemma '+str(c))\n",
    "    evs.set()\n",
    "    print(\"lemmatization finished\")\n",
    "\n",
    "def utilize(qu, ev):\n",
    "    c=0\n",
    "    while not ev.is_set(): # Поддерживаем логику таймаута везде на всякий случай.\n",
    "        try:\n",
    "            t=qu.get(timeout=0.1)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        else:\n",
    "        #processing\n",
    "            c+=1\n",
    "            print('process '+str(c))\n",
    "    print('processing finished')\n",
    "\n",
    "# не надо тормозить при получении данных из очереди,\n",
    "# надо поставить ожидание если очередь пуста.\n",
    "# то, что есть - хороший пример на сложности синхронизации. еще очередь поменьше сделай.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
